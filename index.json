[{"categories":null,"contents":"Addressed pretty significant page load performance issue founde in larger deployments. Eliminates uses of intensive backend query, replacing it with an asynchronous API call against a lucene index. This change reduces page load from from 2+ minutes to nearly instant, with an incredibly responsive UI.\n","permalink":"https://silviadangelo.github.io/projects/contributions/deploy-triggers/","tags":["Java","jQuery","REST APIs","Bamboo","JSON"],"title":"Atlassian Deployment Triggers"},{"categories":null,"contents":"Silvia D’Angelo, Isobel Claire Gormley, Aoife E. McNamara, and Lorraine Brennan (2020).\npreprint available upon request.\nCurrently there is a dearth of methods to model the relationship between multiple biomarkers and single food intake measurements. The multiMarker framework has been developed to address this deficiency, and further allow intake predictions from biomarker data alone. Differently from previous approaches, distributions of predicted intakes are provided, directly accounting for uncertainty in the food intake quantification. multiMarker has been implemented in the form of two homonymous softwares, an R package and a Shiny web application, to facilitate easy access to and widespread use of the framework.\n","permalink":"https://silviadangelo.github.io/publications/bioinformatics20/","tags":null,"title":"multiMarker : an R package and web application to model the relationship between multiple biomarkers and continuous food intake measurements."},{"categories":null,"contents":"Silvia D’Angelo, Lorraine Brennan, and Isobel Claire Gormley (2020).\narXiv.\nMetabolomic based approaches have gained much attention in recent years due to their promising potential to deliver objective tools for assessment of food intake. In particular, multiple biomarkers have emerged for single foods. However, there is a lack of statistical tools available for combining multiple biomarkers to infer food intake. Furthermore, there is a paucity of approaches for estimating the uncertainty around biomarker based prediction of intake. Here, to facilitate inference on the relationship between multiple metabolomic biomarkers and food intake in an intervention study conducted under the A-DIET research programme, a latent variable model, multiMarker, is proposed. The proposed model draws on factor analytic and mixture of experts models, describing intake as a continuous latent variable whose value gives raise to the observed biomarker values. We employ a mixture of Gaussian distributions to flexibly model the latent variable. A Bayesian hierarchical modelling framework provides flexibility to adapt to different biomarker distributions and facilitates prediction of the latent intake along with its associated uncertainty. Simulation studies are conducted to assess the performance of the proposed multiMarker framework, prior to its application to the motivating application of quantifying apple intake.\n","permalink":"https://silviadangelo.github.io/publications/multimarker20/","tags":null,"title":"Inferring food intake from multiple biomarkers using a latent variable model."},{"categories":null,"contents":"D'Angelo,S., Alfò, M. and Murphy, T.B. (2020).\nStatistica Neerlandica.\nMultidimensional network data can have different levels of complexity, as nodes may be characterized by heterogeneous individual‐specific features, which may vary across the networks. This article introduces a class of models for multidimensional network data, where different levels of heterogeneity within and between networks can be considered. The proposed framework is developed in the family of latent space models, and it aims to distinguish symmetric relations between the nodes and node‐specific features. Model parameters are estimated via a Markov Chain Monte Carlo algorithm. Simulated data and an application to a real example, on fruits import/export data, are used to illustrate and comment on the performance of the proposed models.\n","permalink":"https://silviadangelo.github.io/publications/statneerlandica20/","tags":null,"title":"Modelling node heterogeneity in latent space models for multidimensional networks."},{"categories":null,"contents":"D'Angelo,S., Alfò, M. and Fop, M. (2020).\narXiv.\nNetwork data are relational data recorded among a group of individuals, the nodes. Multiple relations observed among the same set of nodes may be represented by means of different networks, using a so-called multidimensional network, or multiplex. We propose a latent space model for network data that enables clustering of the nodes in a latent space, with clusters in this space corresponding to communities of nodes. The clustering structure is modelled using an infinite mixture distribution framework, which allows to perform joint inference on the number of clusters and the cluster parameters. The method is tested on simulated data experiments and is shown in application to a multivariate network among students.\n","permalink":"https://silviadangelo.github.io/publications/arxiv2020/","tags":null,"title":"Model-based clustering for multivariate networks."},{"categories":null,"contents":"D’Angelo, S., Gormley, I.C., McNulty, B.A., Nugent, A.P., Walton, J., Flynn, A. and Brennan, L. (2019).\nAmerican Journal of Clinical Nutrition.\nMeasurement error associated with self-reported dietary intake is a well-documented issue. Combining biomarkers of food intake and dietary intake data is a high priority. The aim of this study was to develop calibration equations for food intake, illustrated with an application for citrus intake. Further, a simulation-based framework was developed to determine the portion of biomarker data needed for stable calibration equation estimation in large population studies. Calibration equations were developed using mean daily self-reported citrus intake (4-d semiweighed food diaries) and biomarker-derived intake (urinary proline betaine biomarker) data from participants (n = 565) as part of a cross-sectional study. Different functional specifications and biomarker transformations were tested to derive the optimal calibration equation specifications. The simulation study was developed using linear regression for the calibration equations. Stability in the calibration equation estimations was investigated for varying portions of biomarker and intake data \u0026ldquo;qualities.\u0026rdquo; With citrus intake, linear regression on nontransformed biomarker data resulted in the optimal calibration equation specifications and produced good-quality predicted intakes. The lowest mean squared error (14,354) corresponded to a linear regression model, defined with biomarker-derived estimates of intakes on the original scale. Using this model in a subpopulation without biomarker data resulted in an average mean plus/minus SD citrus intake of (81-66 g/d, 81+66 g/d). The simulation study suggested that in large population studies, biomarker data on 20-30% of the subjects are required to guarantee stable estimation of calibration equations. This article is accompanied by a web application (\u0026ldquo;Bio-Intake\u0026rdquo;), which was developed to facilitate measurement error correction in self-reported mean daily citrus intake data. Calibration equations proved to be a useful instrument to correct measurement error in self-reported food intake data. The simulation study demonstrated that the use of food intake biomarkers may be feasible and beneficial in the context of large population studies.\nBio-Intake Shiny App: https://adiet.shinyapps.io/Bio-Intake/\n","permalink":"https://silviadangelo.github.io/publications/americanjournalofclinicalnutrition2020/","tags":null,"title":"Combining biomarker and food intake data: calibration equations for citrus intake."},{"categories":null,"contents":"D’Angelo, S., Murphy, T.B. and Alfò, M. (2019).\nAnnals of Applied Statistics.\nThe Eurovision Song Contest is a popular TV singing competition held annually among country members of the European Broadcasting Union. In this competition, each member can be both contestant and jury, as it can participate with a song and/or vote for other countries\u0026rsquo; tunes. During the years, the voting system has repeatedly been accused of being biased by tactical voting; votes would represent strategic interests rather than actual musical preferences of the voting countries. In this work, we develop a latent space model to investigate the presence of a latent structure underlying the exchange of votes. Focusing on the period from 1998 to 2015, we represent the vote exchange as a multivariate network: each edition is a network, where countries are the nodes and two countries are linked by an edge if one voted for the other. The different networks are taken to be independent replicates of a conditional Bernoulli distribution, with success probability specified as a function of a common latent space capturing the overall relationships among the countries. Proximity denotes similarity, and countries close in the latent space are more likely to exchange votes. If the exchange of votes depends on the similarity between countries, the quality of the competing songs might not be a relevant factor in the determination of the voting preferences, and this would suggest the presence of some bias. A Bayesian hierarchical modelling approach is employed to estimate the parameters, where the probability of a connection between any two countries is a function of their distance in the latent space, network-specific parameters and edge-specific covariates. The estimated latent space is found to be relevant in the determination of edge probabilities, however, the positions of the countries in such space only partially correspond to their actual geographical positions.\n","permalink":"https://silviadangelo.github.io/publications/annalsofappliedstatistics2019/","tags":null,"title":"Latent space modeling of multidimensional networks with application to the exchange of votes in the Eurovision Song Contest."},{"categories":null,"contents":"Rivellini, G., Salvatore, M.A., Egidi, V. and D’Angelo, S. (2018).\nDemographic Research.\nMultiple causes of death describe complex death processes marked by the simultaneous presence of several diseases and conditions, primarily at older ages. We intend to explore the opportunity offered by the Social Network Analysis (SNA) in the study of multiple relationships in the causes of death. SNA allowed us to reconstruct the complex system of relationships linking the causes of death mentioned in the same death certificate for Italian men and women aged 65 years and over in 2011. The causes can be represented as actors of a network where the relational tie establishes a linkage between a cause mentioned together with another. The strength of this association is represented by the frequency of the joint mentioning in the same certificate controlling for the confounding effect due to the different prevalence of the causes. The analysis clearly brought out that causes of death describe a very dense system of relationships. Considering only the strongest associations, the graphical analysis showed subgroups of causes, within which cross-references are very frequent while mentions external to the group are rare. Moreover, SNA concepts and instruments allowed us to identify causes playing important roles in death processes and mortality patterns.\n","permalink":"https://silviadangelo.github.io/publications/demographicresearch2018/","tags":null,"title":"A network approach to studying cause-of-death interrelations."},{"categories":null,"contents":"Crispino, M., D’Angelo, S., Ranciati, S., and Mira, A. (2018).\nContributions to Neural Data Science, proceedings of Startup Research, Springer Proceedings in Mathematics and Statistics.\nNeuroscience and neuroimaging have been providing new challenges for statisticians and quantitative researchers in general. As datasets of increasing complexity and dimension become available, the need for statistical techniques to analyze brain related phenomena becomes prominent. In this paper, we delve into data coming from functional Magnetic Resonance Imaging (fMRI) and Diffusion Tensor Imaging (DTI). The aim is to combine information from both sources in order to learn possible patterns of dependencies among regions of interest (ROIs) of the brain. First, we infer positions of these regions in a latent space, using the observed structural connectivity provided by the DTI data, to understand if physical spatial coordinates suitably reflect how ROIs are effectively interconnected. Secondly, we inspect Granger causality in the fMRI data in order to capture patterns of activations between ROIs. Then, we compare results from the analysis on these datasets, to find a link between functional and structural connectivity. Preliminary findings show that latent space positions well reflect hemisphere separation of the brain but are not perfectly connected to all the other structural partitions (that is, lobe, cortex, etc.); furthermore, activations of ROIs inferred from fMRI data are tied to observed structural connections derived from DTI scans.\n","permalink":"https://silviadangelo.github.io/publications/springerproceedings2018/","tags":null,"title":"Understanding dependency patterns in structural and functional brain connectivity through fMRI and DTI data."},{"categories":null,"contents":"Shields.io is a massive library of badges that can be inserted into project README's or websites displaying various statuses (code coverage, health, version, etc). Support for docker was missing the current build health, and was a pretty trivial addition.\n","permalink":"https://silviadangelo.github.io/projects/contributions/shields-docker/","tags":["Docker","Rest APIs","JavaScript","node.js","JSON"],"title":"Added Docker Build Status Badge to shields.io"},{"categories":null,"contents":"While adding Structured Data to a client's website I found some example JSON that was invalid. Simple contribution to cleanup the user documentation providing syntactically valid JSON documents.\n","permalink":"https://silviadangelo.github.io/projects/contributions/schema-org/","tags":["JSON"],"title":"Schema.org Structured Data documentation fixes"},{"categories":null,"contents":"BOSH (Bosh Outer SHell) \u0026ldquo;\u0026hellip;is an open source tool for release engineering, deployment, lifecycle management, and monitoring of distributed systems.\u0026rdquo; And it's amazingly powerful. This examples uses BOSH to provision an Alassian vendor app running on JDK along with the support Postgres database and agents to support it. The releases manages the health of services and will automatically provision, start/stop processes across the various services.\n","permalink":"https://silviadangelo.github.io/projects/creations/bosh-agents/","tags":["DevOps","BOSH","Java","Atlassian Ecosystem","monit","python","xml/xslt","bash/shell","REST APIs"],"title":"BOSH release for Bamboo \u0026 Remote Agents"},{"categories":["R"],"contents":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","permalink":"https://silviadangelo.github.io/blog/2015-07-23-r-rmarkdown/","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown"},{"categories":null,"contents":"Intro Doesn't matter whether it's a CakePHP app for a client, your own personal CMS, or any other web based application. If your passing around passwords or other sensitive info you should really implement SSL. SSL provides 2 main perks to your visitors.\n First it encrypts all communication that flies across the web. This prevents curious or devious billies from getting your secrets. Secondly it ensures to the user that your server is in fact who it claims, and not a nasty \u0026lsquo;man in the middle\u0026rdquo; attack. Finally it gives your site that touch of class\u0026hellip;. which of course a classy person like yourself relies on.  Once you implement SSL certificates on your server you'll want to require secure connections using Apache's rewrite module. Now I won't dwell on the creation and signing of certificates, its already well documented. If your just starting out though,heres a few links I recommend;\n Creating self-signed certificates (free, but should only be used internally or for testing, users will; see an \u0026lsquo;Untrusted\u0026rdquo; warning) Requesting a CA Signed certificate (not free, but the final certificate is trusted and seamless for users)  The second link uses the schools internal CA, you will need to pay a public CA like Entrust or Verisign. All of this information is aimed at \u0026lsquo;nix or solaris servers running apache. Why? cause a production windows server is laughable :-p\nNow that you have a certificate, whats next? So there you are you have a shiny new Certificate and Server key, how do you force visitors to your apache driven site to use the SSL? You copied the certificates into the appropite locations right? And you have made the needed changes in httpd.conf right? So now when you view https://example.com you see a \u0026lsquo;trusted\u0026rsquo; warning or your site right? If No to any of these than this article does a pretty good job of outlining those steps.\nThe SSL Works, How do I force connections to use it? First you need to decide if you want to force every page on your site to use SSL, or only a particular sub-domain, or maybe just your admin directory. Since the overhead is minimal there is no harm is forcing the entire domain to leverage SSL, but if it is a self-signed certificate for your personal use than you'll most certainly want to restrict its use to your own areas. This prevents users from seeing that nasty warning \u0026ldquo;This server is not trusted\u0026rdquo; You'll know if your using SSL because the url prefix changes from http to https (s for secure).\nForcing entire domain to use SSL You want any visit, any where to use ssl. This probably the simplest solution. Create or append to your htaccess file in the top directory of your server. Some people use a port check (80 is typically http, while 443 is https) but if you have alernate configs or the user just adds :8080 to the end of the url this method is useless. Instead check whether the https environmental variable is set, if not then redirect.\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://%{SERVER_NAME}$1 \\[R,L\\] Forcing sub-domains to use SSL Maybe you only want mysecretarea.example.com to use SSL, that's easy enough. Its the same premise as above, but you move the htaccess file into the directory that corresponds to the subdomain. Also change the second line like below;\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://mysecretarea.%{SERVER_NAME}$1 \\[R,L\\] Forcing a directory to use SSL This method cn get a little hairier if your using aliases or redirects on top of this one. You'll need to consider what order the commands are read. The basic principle is like so. You want all visits to example.com/admin to use ssl. Create a htaccess file in the parent directory. Again will check for the https variable, but this time we also check for the sub-directory to be in the path.\nRewriteCond %{HTTPS} !=on RewriteRule ^/admin/(.*)$ https://%{SERVER_NAME}/admin/$1 \\[R,L\\] ","permalink":"https://silviadangelo.github.io/blog/force-ssl/","tags":["apache","apache","redirect","rewrite","ssl","web development"],"title":"Forcing Visits to use SSL"},{"categories":null,"contents":"Multiple plugins used by thousands of teams that provide enhanced functionality of Atlassian’s core products (primarily JIRA and Bamboo) to enrich CI/CD capabilities, DevOps automation, or productivity. Functionality spans user interface, web services and persistence.\n","permalink":"https://silviadangelo.github.io/projects/creations/marketplace/","tags":["Java","Spring","REST APIs","Javascript","Atlassian Developer Ecosystem","Bamboo","JIRA","Bitbucket","Confluence","DevOps"],"title":"Atlassian Marketplace Plugins"},{"categories":null,"contents":"Provides required dependencies and additional utilities to simplify and codify the process of building, testing and delivering Atlassian plugins all the way to the live marketplace.Executes integration/AUT level tests against all stated compatible versions for the productUploads generated artifact to Atlassian marketplaceProvides corresponding metadata indicating version, release notes, and compatibility","permalink":"https://silviadangelo.github.io/projects/creations/docker-marketplace/","tags":["Docker","Maven","Java","Python","REST APIs","Bash/Shell"],"title":"Docker image for Bitbucket CI/CD Pipelines  \"shipit\""},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026quot;HTML\u0026quot;, \u0026quot;JSON\u0026quot;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026quot;contents\u0026quot;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026quot;tags\u0026quot;:{{ .Params.tags | jsonify }}{{end}}, \u0026quot;categories\u0026quot; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026quot;title\u0026quot;, \u0026quot;contents\u0026quot;, \u0026quot;tags\u0026quot;, \u0026quot;categories\u0026quot; ] ","permalink":"https://silviadangelo.github.io/search/","tags":null,"title":"Search Results"}]